"""AsciiImagesC64 dataset."""
import os
import random

import tensorflow_datasets as tfds
import tensorflow as tf
import pandas as pd
import numpy as np

_DESCRIPTION = """
This dataset consists of images generated by running the PerfectAsciiConverter (with a C64 character set)
on a series of color images. The source images were preprocessed by first converting them to high contrast
black and white images with the Otsu filter run on each 8x8 block of the image, and subsequently fed to the
ASCII converter, which matched each of these blocks to the closest C64 character available in the character set.

Each text file is a tab delimited CSV which is the result of running this process over one source image. Each line
in the file represents one training example, or one processed 8x8 binary block of the source image. The first column 
represents the label (ID of the character chosen for this particular block), and columns 2-65 the binary pixel data
of the source image in 0-1 range.
"""

# TODO(AsciiImagesC64): BibTeX citation
_CITATION = """
"""


class AsciiImagesC64(tfds.core.GeneratorBasedBuilder):
    """DatasetBuilder for AsciiImagesC64 dataset."""

    VERSION = tfds.core.Version('1.6.5')
    RELEASE_NOTES = {
        '1.6.5': 'Only uses half (about 50 images) of total dataset. Converted using the new C64-ext character set (362 characters). Added 45 new images to dataset, for a total of 106. New stills added from Bladerunner 1982, '
                 'Thor: Ragnarok and Tron Legacy.',
    }

    def _info(self) -> tfds.core.DatasetInfo:
        """Returns the dataset metadata."""
        # TODO(AsciiImagesC64): Specifies the tfds.core.DatasetInfo object
        return tfds.core.DatasetInfo(
            builder=self,
            description=_DESCRIPTION,
            features=tfds.features.FeaturesDict({
                # The label is a 2 byte integer representing the index of the ASCII character which matches
                # the 8x8 image block
                'image': tfds.features.Image(
                    shape=(8, 8, 1),
                    dtype=np.uint8
                ),
                'label': tfds.features.ClassLabel(
                    num_classes=362
                )

            }),
            # If there's a common (input, target) tuple from the
            # features, specify them here. They'll be used if
            # `as_supervised=True` in `builder.as_dataset`.
            supervised_keys=('image', 'label'),  # Set to `None` to disable
            homepage='https://www.example.com/',
            citation=_CITATION,
        )

    def _split_generators(self, dl_manager: tfds.download.DownloadManager):
        """Returns SplitGenerators."""
        path = "data"
        pwd = os.path.dirname(os.path.realpath(__file__))

        train_dir = os.path.join(pwd, 'data/train')
        test_dir = os.path.join(pwd, 'data/test')

        # There is no predefined train/val/test split for this dataset, so only return one
        # Split and split the data later: https://www.tensorflow.org/datasets/splits
        return {
            'train': self._generate_examples(path=train_dir)
            # 'test':  self._generate_examples(path=test_dir)
        }

    def _generate_examples(self, path):
        """Yields examples."""

        file_list = tf.data.Dataset.list_files(path + "/*ascii-data.txt")

        all_label_data = []
        all_image_data = []

        for file in file_list:
            filename = file.numpy().decode("utf-8")
            df = pd.read_csv(filename, sep='\t', header=None)
            all_data = df.to_numpy(dtype=np.uint16)


            # Extract labels from file
            label_data = all_data[:, 0:1]
            label_data = label_data.flatten()

            # Extract image data from file
            image_data = all_data[:, 1:]
            image_data = image_data * 255
            image_data = image_data.astype('uint8')

            for label, image in zip(label_data, image_data):
                all_label_data.append(label)
                all_image_data.append(image.reshape(8,8,1))


        for label, image in zip(all_label_data, all_image_data):
            image_id = random.getrandbits(256) # Auto generate key
            yield image_id, {
                'image': image,
                'label': label,
            }


    @classmethod
    def load_dataset(cls, split, batch_size=24, version=None, shuffle=True):
        dataset_name = cls.__name__
        dataset_name = f'{dataset_name}:{version}' if version else dataset_name
        dataset, info = tfds.load(
            dataset_name,
            split=split,
            shuffle_files=True,
            as_supervised=True,
            with_info=True
        )

        print(f'==== Loaded dataset {dataset_name} ====')
        print(f'Examples: {info.splits["train"].num_examples:,}')
        print(f'Size:{info.dataset_size}')

        if shuffle:
            dataset = dataset.shuffle(750000, reshuffle_each_iteration=True)

        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
        dataset = dataset.batch(batch_size, drop_remainder=False)

        return dataset, info